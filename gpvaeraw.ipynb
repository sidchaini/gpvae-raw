{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e72cb4db-007e-45b2-b779-75fd21aa34ca",
   "metadata": {},
   "source": [
    "- https://www.kaggle.com/siddharthchaini/gp-vae-intro\n",
    "- https://github.com/siddharthchaini/GP-VAE/blob/master/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e876bd-b11b-42b1-b1f3-e1afdd781d8b",
   "metadata": {},
   "source": [
    "### Download Physionet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b833d05-356a-45d5-a252-a20ea3d66111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/651d86winb4cy9n/physionet.npz?dl=1 -O physionet.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8776a3-b2d8-44d3-a07e-2530c3fbe39d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d24fdf-5b6d-463c-8fb7-783299d1346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f0c4f-51f7-4916-b281-db7de0964da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff0b5c-615a-445f-a90a-7229093b2f63",
   "metadata": {},
   "source": [
    "### Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0657fed-aede-4d28-af01-b1afd0b87791",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 35 # 'Dimensionality of the latent space'\n",
    "encoder_sizes = [128, 128] # 'Layer sizes of the encoder'\n",
    "decoder_sizes = [256, 256] # 'Layer sizes of the decoder'\n",
    "window_size = 24 # 'Window size for the inference CNN: Ignored if model_type is not gp-vae'\n",
    "sigma = 1.005 # 'Sigma value for the GP prior: Ignored if model_type is not gp-vae'\n",
    "length_scale = 7.0 # 'Length scale value for the GP prior: Ignored if model_type is not gp-vae'\n",
    "beta = 0.2 # 'Factor to weigh the KL term (similar to beta-VAE'\n",
    "num_epochs = 40 # 'Number of training epochs'\n",
    "\n",
    "# Flags with common default values for all three datasets\n",
    "learning_rate = 1e-3 # 'Learning rate for training'\n",
    "gradient_clip = 1e4 # 'Maximum global gradient norm for the gradient clipping during training'\n",
    "num_steps = 0 # 'Number of training steps: If non-zero it overwrites num_epochs'\n",
    "print_interval = 0 # 'Interval for printing the loss and saving the model during training'\n",
    "exp_name = \"reproduce_physionet\" # 'Name of the experiment'\n",
    "basedir = \"models\" # 'Directory where the models should be stored'\n",
    "data_dir = \"\" # 'Directory from where the data should be read in'\n",
    "data_type = 'physionet' # ['hmnist', 'physionet', 'sprites'], 'Type of data to be trained on'\n",
    "seed = 1337 # 'Seed for the random number generator'\n",
    "model_type = 'gp-vae' # ['vae', 'hi-vae', 'gp-vae'], 'Type of model to be trained'\n",
    "cnn_kernel_size = 3 # 'Kernel size for the CNN preprocessor'\n",
    "cnn_sizes = [256] # 'Number of filters for the layers of the CNN preprocessor'\n",
    "testing = True # 'Use the actual test set for testing'\n",
    "banded_covar = True # 'Use a banded covariance matrix instead of a diagonal one for the output of the inference network: Ignored if model_type is not gp-vae'\n",
    "batch_size = 64 # 'Batch size for training'\n",
    "\n",
    "M = 1 # 'Number of samples for ELBO estimation'\n",
    "K = 1 # 'Number of importance sampling weights'\n",
    "\n",
    "kernel = 'cauchy' # ['rbf', 'diffusion', 'matern', 'cauchy'], 'Kernel to be used for the GP prior: Ignored if model_type is not (mgp-vae'\n",
    "kernel_scales = 1 # 'Number of different length scales sigma for the GP prior: Ignored if model_type is not gp-vae'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec16aa90-d161-43a7-b2b5-ede1379db293",
   "metadata": {},
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9512f-b004-4159-ba0c-5dda5fad6af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "print(\"Testing: \", testing, f\"\\t Seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd190af-9173-43e9-b27c-96241c4ea5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_sizes = [int(size) for size in encoder_sizes]\n",
    "decoder_sizes = [int(size) for size in decoder_sizes]\n",
    "\n",
    "if 0 in encoder_sizes:\n",
    "    encoder_sizes.remove(0)\n",
    "if 0 in decoder_sizes:\n",
    "    decoder_sizes.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4ba8d-f039-4701-9c5b-fd51c2b95b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make up full exp name\n",
    "timestamp = datetime.now().strftime(\"%y%m%d\")\n",
    "full_exp_name = \"{}_{}\".format(timestamp, exp_name)\n",
    "outdir = os.path.join(basedir, full_exp_name)\n",
    "if not os.path.exists(outdir): os.mkdir(outdir)\n",
    "checkpoint_prefix = os.path.join(outdir, \"ckpt\")\n",
    "print(\"Full exp name: \", full_exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b9da4-4500-4c37-826e-9ae984d69fc3",
   "metadata": {},
   "source": [
    "### Define data specific parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cc6e4-e375-4a55-abe5-d3261110f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef24ef-0ff4-4759-8842-da3ecf12c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == \"hmnist\":\n",
    "    data_dir = \"data/hmnist/hmnist_mnar.npz\"\n",
    "    data_dim = 784\n",
    "    time_length = 10\n",
    "    num_classes = 10\n",
    "    decoder = BernoulliDecoder\n",
    "    img_shape = (28, 28, 1)\n",
    "    val_split = 50000\n",
    "elif data_type == \"physionet\":\n",
    "    if data_dir == \"\":\n",
    "        data_dir = \"physionet.npz\"\n",
    "    data_dim = 35\n",
    "    time_length = 48\n",
    "    num_classes = 2\n",
    "    decoder = GaussianDecoder\n",
    "elif data_type == \"sprites\":\n",
    "    if data_dir == \"\":\n",
    "        data_dir = \"data/sprites/sprites.npz\"\n",
    "    data_dim = 12288\n",
    "    time_length = 8\n",
    "    decoder = GaussianDecoder\n",
    "    img_shape = (64, 64, 3)\n",
    "    val_split = 8000\n",
    "else:\n",
    "    raise ValueError(\"Data type must be one of ['hmnist', 'physionet', 'sprites']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e476b-fcce-4220-965f-0e11875f574d",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b66f9-3279-4e30-896d-5a806eb5e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b369bc-da04-464b-9965-c3a42fee6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full = data['x_train_full']\n",
    "x_train_miss = data['x_train_miss']\n",
    "m_train_miss = data['m_train_miss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0e594-772b-43cb-8567-ecdd8ad7c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type in ['hmnist', 'physionet']:\n",
    "    y_train = data['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f530935-237a-43c0-8b41-bc2427236e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing:\n",
    "    if data_type in ['hmnist', 'sprites']:\n",
    "        x_val_full = data['x_test_full']\n",
    "        x_val_miss = data['x_test_miss']\n",
    "        m_val_miss = data['m_test_miss']\n",
    "    if data_type == 'hmnist':\n",
    "        y_val = data['y_test']\n",
    "    elif data_type == 'physionet':\n",
    "        x_val_full = data['x_train_full']\n",
    "        x_val_miss = data['x_train_miss']\n",
    "        m_val_miss = data['m_train_miss']\n",
    "        y_val = data['y_train']\n",
    "        m_val_artificial = data[\"m_train_artificial\"]\n",
    "elif data_type in ['hmnist', 'sprites']:\n",
    "    x_val_full = x_train_full[val_split:]\n",
    "    x_val_miss = x_train_miss[val_split:]\n",
    "    m_val_miss = m_train_miss[val_split:]\n",
    "    if data_type == 'hmnist':\n",
    "        y_val = y_train[val_split:]\n",
    "    x_train_full = x_train_full[:val_split]\n",
    "    x_train_miss = x_train_miss[:val_split]\n",
    "    m_train_miss = m_train_miss[:val_split]\n",
    "    y_train = y_train[:val_split]\n",
    "elif data_type == 'physionet':\n",
    "    x_val_full = data[\"x_val_full\"]  # full for artificial missings\n",
    "    x_val_miss = data[\"x_val_miss\"]\n",
    "    m_val_miss = data[\"m_val_miss\"]\n",
    "    m_val_artificial = data[\"m_val_artificial\"]\n",
    "    y_val = data[\"y_val\"]\n",
    "else:\n",
    "    raise ValueError(\"Data type must be one of ['hmnist', 'physionet', 'sprites']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc7cef-b3ca-4d05-bc66-6f40d5683814",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_x_train_miss = tf.data.Dataset.from_tensor_slices((x_train_miss, m_train_miss))\\\n",
    "                                 .shuffle(len(x_train_miss)).batch(batch_size).repeat()\n",
    "tf_x_val_miss = tf.data.Dataset.from_tensor_slices((x_val_miss, m_val_miss)).batch(batch_size).repeat()\n",
    "tf_x_val_miss = tf.compat.v1.data.make_one_shot_iterator(tf_x_val_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cbb0c-5b87-4801-a189-34d1be170420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Conv2D preprocessor for image data\n",
    "if data_type in ['hmnist', 'sprites']:\n",
    "    print(\"Using CNN preprocessor\")\n",
    "    image_preprocessor = ImagePreprocessor(img_shape, cnn_sizes, cnn_kernel_size)\n",
    "elif data_type == 'physionet':\n",
    "    image_preprocessor = None\n",
    "else:\n",
    "    raise ValueError(\"Data type must be one of ['hmnist', 'physionet', 'sprites']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c826df-5434-4f3e-8f4c-1e7e54344498",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2a33f-0995-49df-9bf6-bbc0f4470f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"vae\":\n",
    "    model = VAE(latent_dim=latent_dim, data_dim=data_dim, time_length=time_length,\n",
    "                encoder_sizes=encoder_sizes, encoder=DiagonalEncoder,\n",
    "                decoder_sizes=decoder_sizes, decoder=decoder,\n",
    "                image_preprocessor=image_preprocessor, window_size=window_size,\n",
    "                beta=beta, M=M, K=K)\n",
    "elif model_type == \"hi-vae\":\n",
    "    model = HI_VAE(latent_dim=latent_dim, data_dim=data_dim, time_length=time_length,\n",
    "                   encoder_sizes=encoder_sizes, encoder=DiagonalEncoder,\n",
    "                   decoder_sizes=decoder_sizes, decoder=decoder,\n",
    "                   image_preprocessor=image_preprocessor, window_size=window_size,\n",
    "                   beta=beta, M=M, K=K)\n",
    "elif model_type == \"gp-vae\":\n",
    "    encoder = BandedJointEncoder if banded_covar else JointEncoder\n",
    "    model = GP_VAE(latent_dim=latent_dim, data_dim=data_dim, time_length=time_length,\n",
    "                   encoder_sizes=encoder_sizes, encoder=encoder,\n",
    "                   decoder_sizes=decoder_sizes, decoder=decoder,\n",
    "                   kernel=kernel, sigma=sigma,\n",
    "                   length_scale=length_scale, kernel_scales = kernel_scales,\n",
    "                   image_preprocessor=image_preprocessor, window_size=window_size,\n",
    "                   beta=beta, M=M, K=K, data_type=data_type)\n",
    "else:\n",
    "    raise ValueError(\"Model type must be one of ['vae', 'hi-vae', 'gp-vae']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373e1f6-fe6b-4274-8a25-f08d1728452f",
   "metadata": {},
   "source": [
    "### Training preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ac1fe-0c95-4eee-946e-70ee2e44a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU support: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db5386c-ab4e-40c8-8192-9f09e6da68e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training...\")\n",
    "_ = tf.compat.v1.train.get_or_create_global_step()\n",
    "trainable_vars = model.get_trainable_vars()\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "print(\"Encoder: \", model.encoder.net.summary())\n",
    "print(\"Decoder: \", model.decoder.net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe28b8-1154-4bd1-a4a2-4bcc482b6032",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.preprocessor is not None:\n",
    "    print(\"Preprocessor: \", model.preprocessor.net.summary())\n",
    "    saver = tf.compat.v1.train.Checkpoint(optimizer=optimizer, encoder=model.encoder.net,\n",
    "                                          decoder=model.decoder.net, preprocessor=model.preprocessor.net,\n",
    "                                          optimizer_step=tf.compat.v1.train.get_or_create_global_step())\n",
    "else:\n",
    "    saver = tf.compat.v1.train.Checkpoint(optimizer=optimizer, encoder=model.encoder.net, decoder=model.decoder.net,\n",
    "                                          optimizer_step=tf.compat.v1.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de9f77-54a8-479a-82a0-895a4e771400",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = tf.compat.v2.summary.create_file_writer(logdir=outdir, flush_millis=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be32f80-b9b0-4a90-b234-3a24dfd7b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_steps == 0:\n",
    "    num_steps = num_epochs * len(x_train_miss) // batch_size\n",
    "else:\n",
    "    num_steps = num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9150cc1-087d-4ad6-be39-4d7279300aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_interval == 0:\n",
    "    print_interval = num_steps // num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a1c63-372e-49ee-8c06-bf5c294efbac",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2142e9a-7bea-434c-9be8-e4bb960665ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_train = []\n",
    "losses_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582fdb7f-06c6-41a2-950c-f84bfaa23ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6ca16-38d3-4b93-b011-ad4afaac03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with summary_writer.as_default(), tf.compat.v2.summary.record_if(True):\n",
    "    for i, (x_seq, m_seq) in enumerate(tf_x_train_miss.take(num_steps)):\n",
    "        try:\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(trainable_vars)\n",
    "                loss = model.compute_loss(x_seq, m_mask=m_seq)\n",
    "                losses_train.append(loss.numpy())\n",
    "            grads = tape.gradient(loss, trainable_vars)\n",
    "            grads = [np.nan_to_num(grad) for grad in grads]\n",
    "            grads, global_norm = tf.clip_by_global_norm(grads, gradient_clip)\n",
    "            optimizer.apply_gradients(zip(grads, trainable_vars),\n",
    "                                      global_step=tf.compat.v1.train.get_or_create_global_step())\n",
    "\n",
    "            # Print intermediate results\n",
    "            if i % print_interval == 0:\n",
    "                print(\"================================================\")\n",
    "                print(\"Learning rate: {} | Global gradient norm: {:.2f}\".format(optimizer._lr, global_norm))\n",
    "                print(\"Step {}) Time = {:2f}\".format(i, time.time() - t0))\n",
    "                loss, nll, kl = model.compute_loss(x_seq, m_mask=m_seq, return_parts=True)\n",
    "                print(\"Train loss = {:.3f} | NLL = {:.3f} | KL = {:.3f}\".format(loss, nll, kl))\n",
    "\n",
    "                saver.save(checkpoint_prefix)\n",
    "                tf.compat.v2.summary.scalar(name=\"loss_train\", data=loss, step=tf.compat.v1.train.get_or_create_global_step())\n",
    "                tf.compat.v2.summary.scalar(name=\"kl_train\", data=kl, step=tf.compat.v1.train.get_or_create_global_step())\n",
    "                tf.compat.v2.summary.scalar(name=\"nll_train\", data=nll, step=tf.compat.v1.train.get_or_create_global_step())\n",
    "\n",
    "                # Validation loss\n",
    "                x_val_batch, m_val_batch = tf_x_val_miss.get_next()\n",
    "                val_loss, val_nll, val_kl = model.compute_loss(x_val_batch, m_mask=m_val_batch, return_parts=True)\n",
    "                losses_val.append(val_loss.numpy())\n",
    "                print(\"Validation loss = {:.3f} | NLL = {:.3f} | KL = {:.3f}\".format(val_loss, val_nll, val_kl))\n",
    "\n",
    "                tf.compat.v2.summary.scalar(name=\"loss_val\", data=val_loss, step=tf.compat.v1.train.get_or_create_global_step())\n",
    "                tf.compat.v2.summary.scalar(name=\"kl_val\", data=val_kl, step=tf.compat.v1.train.get_or_create_global_step())\n",
    "                tf.compat.v2.summary.scalar(name=\"nll_val\", data=val_nll, step=tf.compat.v1.train.get_or_create_global_step())\n",
    "\n",
    "                if data_type in [\"hmnist\", \"sprites\"]:\n",
    "                    # Draw reconstructed images\n",
    "                    x_hat = model.decode(model.encode(x_seq).sample()).mean()\n",
    "                    tf.compat.v2.summary.image(name=\"input_train\", data=tf.reshape(x_seq, [-1]+list(img_shape)), step=tf.compat.v1.train.get_or_create_global_step())\n",
    "                    tf.compat.v2.summary.image(name=\"reconstruction_train\", data=tf.reshape(x_hat, [-1]+list(img_shape)), step=tf.compat.v1.train.get_or_create_global_step())\n",
    "                elif data_type == 'physionet':\n",
    "                    # Eval MSE and AUROC on entire val set\n",
    "                    x_val_miss_batches = np.array_split(x_val_miss, batch_size, axis=0)\n",
    "                    x_val_full_batches = np.array_split(x_val_full, batch_size, axis=0)\n",
    "                    m_val_artificial_batches = np.array_split(m_val_artificial, batch_size, axis=0)\n",
    "                    get_val_batches = lambda: zip(x_val_miss_batches, x_val_full_batches, m_val_artificial_batches)\n",
    "\n",
    "                    n_missings = m_val_artificial.sum()\n",
    "                    mse_miss = np.sum([model.compute_mse(x, y=y, m_mask=m).numpy()\n",
    "                                       for x, y, m in get_val_batches()]) / n_missings\n",
    "\n",
    "                    x_val_imputed = np.vstack([model.decode(model.encode(x_batch).mean()).mean().numpy()\n",
    "                                               for x_batch in x_val_miss_batches])\n",
    "                    x_val_imputed[m_val_miss == 0] = x_val_miss[m_val_miss == 0]  # impute gt observed values\n",
    "\n",
    "                    x_val_imputed = x_val_imputed.reshape([-1, time_length * data_dim])\n",
    "                    val_split = len(x_val_imputed) // 2\n",
    "                    cls_model = LogisticRegression(solver='liblinear', tol=1e-10, max_iter=10000)\n",
    "                    cls_model.fit(x_val_imputed[:val_split], y_val[:val_split])\n",
    "                    probs = cls_model.predict_proba(x_val_imputed[val_split:])[:, 1]\n",
    "                    auroc = roc_auc_score(y_val[val_split:], probs)\n",
    "                    print(\"MSE miss: {:.4f} | AUROC: {:.4f}\".format(mse_miss, auroc))\n",
    "\n",
    "                    # Update learning rate (used only for physionet with decay=0.5)\n",
    "                    if i > 0 and i % (10*print_interval) == 0:\n",
    "                        optimizer._lr = max(0.5 * optimizer._lr, 0.1 * learning_rate)\n",
    "                t0 = time.time()\n",
    "        except KeyboardInterrupt as e:\n",
    "            print(\"KeyboardInterrupt\")\n",
    "            saver.save(checkpoint_prefix)\n",
    "#             if debug:\n",
    "#                 import ipdb\n",
    "#                 ipdb.set_trace()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c9a6d-cd7b-498b-9505-d391f5b03864",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59627238-ae25-4b33-bc7f-aaaea7036887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data on batches\n",
    "x_val_miss_batches = np.array_split(x_val_miss, batch_size, axis=0)\n",
    "x_val_full_batches = np.array_split(x_val_full, batch_size, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a81f0-a506-44a4-b504-81deb6b9f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'physionet':\n",
    "    m_val_batches = np.array_split(m_val_artificial, batch_size, axis=0)\n",
    "else:\n",
    "    m_val_batches = np.array_split(m_val_miss, batch_size, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5317a2-b4b1-4d6e-ad1f-11e3b1f5ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_val_batches = lambda: zip(x_val_miss_batches, x_val_full_batches, m_val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9254f-57ab-42cc-8264-bce3501ea06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute NLL and MSE on missing values\n",
    "n_missings = m_val_artificial.sum() if data_type == 'physionet' else m_val_miss.sum()\n",
    "nll_miss = np.sum([model.compute_nll(x, y=y, m_mask=m).numpy()\n",
    "                   for x, y, m in get_val_batches()]) / n_missings\n",
    "mse_miss = np.sum([model.compute_mse(x, y=y, m_mask=m, binary=data_type==\"hmnist\").numpy()\n",
    "                   for x, y, m in get_val_batches()]) / n_missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f91fba-fb1b-476a-a530-6244e7fc3d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NLL miss: {:.4f}\".format(nll_miss))\n",
    "print(\"MSE miss: {:.4f}\".format(mse_miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c585ae40-6de8-4790-b1ed-e41c7952370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save imputed values\n",
    "z_mean = [model.encode(x_batch).mean().numpy() for x_batch in x_val_miss_batches]\n",
    "np.save(os.path.join(outdir, \"z_mean\"), np.vstack(z_mean))\n",
    "x_val_imputed = np.vstack([model.decode(z_batch).mean().numpy() for z_batch in z_mean])\n",
    "np.save(os.path.join(outdir, \"imputed_no_gt\"), x_val_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5c478-cafc-4aa6-995b-89203b8882b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute gt observed values\n",
    "x_val_imputed[m_val_miss == 0] = x_val_miss[m_val_miss == 0]\n",
    "np.save(os.path.join(outdir, \"imputed\"), x_val_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89972973-de0a-4ea0-b816-f6d6e22480b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == \"hmnist\":\n",
    "    # AUROC evaluation using Logistic Regression\n",
    "    x_val_imputed = np.round(x_val_imputed)\n",
    "    x_val_imputed = x_val_imputed.reshape([-1, time_length * data_dim])\n",
    "\n",
    "    cls_model = LogisticRegression(solver='lbfgs', multi_class='multinomial', tol=1e-10, max_iter=10000)\n",
    "    val_split = len(x_val_imputed) // 2\n",
    "\n",
    "    cls_model.fit(x_val_imputed[:val_split], y_val[:val_split])\n",
    "    probs = cls_model.predict_proba(x_val_imputed[val_split:])\n",
    "\n",
    "    auprc = average_precision_score(np.eye(num_classes)[y_val[val_split:]], probs)\n",
    "    auroc = roc_auc_score(np.eye(num_classes)[y_val[val_split:]], probs)\n",
    "    print(\"AUROC: {:.4f}\".format(auroc))\n",
    "    print(\"AUPRC: {:.4f}\".format(auprc))\n",
    "\n",
    "elif data_type == \"sprites\":\n",
    "    auroc, auprc = 0, 0\n",
    "\n",
    "elif data_type == \"physionet\":\n",
    "    # Uncomment to preserve some z_samples and their reconstructions\n",
    "    # for i in range(5):\n",
    "    #     z_sample = [model.encode(x_batch).sample().numpy() for x_batch in x_val_miss_batches]\n",
    "    #     np.save(os.path.join(outdir, \"z_sample_{}\".format(i)), np.vstack(z_sample))\n",
    "    #     x_val_imputed_sample = np.vstack([model.decode(z_batch).mean().numpy() for z_batch in z_sample])\n",
    "    #     np.save(os.path.join(outdir, \"imputed_sample_{}_no_gt\".format(i)), x_val_imputed_sample)\n",
    "    #     x_val_imputed_sample[m_val_miss == 0] = x_val_miss[m_val_miss == 0]\n",
    "    #     np.save(os.path.join(outdir, \"imputed_sample_{}\".format(i)), x_val_imputed_sample)\n",
    "\n",
    "    # AUROC evaluation using Logistic Regression\n",
    "    x_val_imputed = x_val_imputed.reshape([-1, time_length * data_dim])\n",
    "    val_split = len(x_val_imputed) // 2\n",
    "    cls_model = LogisticRegression(solver='liblinear', tol=1e-10, max_iter=10000)\n",
    "    cls_model.fit(x_val_imputed[:val_split], y_val[:val_split])\n",
    "    probs = cls_model.predict_proba(x_val_imputed[val_split:])[:, 1]\n",
    "    auprc = average_precision_score(y_val[val_split:], probs)\n",
    "    auroc = roc_auc_score(y_val[val_split:], probs)\n",
    "\n",
    "    print(\"AUROC: {:.4f}\".format(auroc))\n",
    "    print(\"AUPRC: {:.4f}\".format(auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82906280-498a-46da-ace5-90f4e5d3be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstructions\n",
    "if data_type in [\"hmnist\", \"sprites\"]:\n",
    "    img_index = 0\n",
    "    if data_type == \"hmnist\":\n",
    "        img_shape = (28, 28)\n",
    "        cmap = \"gray\"\n",
    "    elif data_type == \"sprites\":\n",
    "        img_shape = (64, 64, 3)\n",
    "        cmap = None\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=x_val_miss.shape[1], figsize=(2*x_val_miss.shape[1], 6))\n",
    "\n",
    "    x_hat = model.decode(model.encode(x_val_miss[img_index: img_index+1]).mean()).mean().numpy()\n",
    "    seqs = [x_val_miss[img_index:img_index+1], x_hat, x_val_full[img_index:img_index+1]]\n",
    "\n",
    "    for axs, seq in zip(axes, seqs):\n",
    "        for ax, img in zip(axs, seq[0]):\n",
    "            ax.imshow(img.reshape(img_shape), cmap=cmap)\n",
    "            ax.axis('off')\n",
    "\n",
    "    suptitle = model_type + f\" reconstruction, NLL missing = {mse_miss}\"\n",
    "    fig.suptitle(suptitle, size=18)\n",
    "    fig.savefig(os.path.join(outdir, data_type + \"_reconstruction.pdf\"))\n",
    "\n",
    "results_all = [seed, model_type, data_type, kernel, beta, latent_dim,\n",
    "               num_epochs, batch_size, learning_rate, window_size,\n",
    "               kernel_scales, sigma, length_scale,\n",
    "               len(encoder_sizes), encoder_sizes[0] if len(encoder_sizes) > 0 else 0,\n",
    "               len(decoder_sizes), decoder_sizes[0] if len(decoder_sizes) > 0 else 0,\n",
    "               cnn_kernel_size, cnn_sizes,\n",
    "               nll_miss, mse_miss, losses_train[-1], losses_val[-1], auprc, auroc, testing, data_dir]\n",
    "\n",
    "with open(os.path.join(outdir, \"results.tsv\"), \"w\") as outfile:\n",
    "    outfile.write(\"seed\\tmodel\\tdata\\tkernel\\tbeta\\tz_size\\tnum_epochs\"\n",
    "                  \"\\tbatch_size\\tlearning_rate\\twindow_size\\tkernel_scales\\t\"\n",
    "                  \"sigma\\tlength_scale\\tencoder_depth\\tencoder_width\\t\"\n",
    "                  \"decoder_depth\\tdecoder_width\\tcnn_kernel_size\\t\"\n",
    "                  \"cnn_sizes\\tNLL\\tMSE\\tlast_train_loss\\tlast_val_loss\\tAUPRC\\tAUROC\\ttesting\\tdata_dir\\n\")\n",
    "    outfile.write(\"\\t\".join(map(str, results_all)))\n",
    "\n",
    "with open(os.path.join(outdir, \"training_curve.tsv\"), \"w\") as outfile:\n",
    "    outfile.write(\"\\t\".join(map(str, losses_train)))\n",
    "    outfile.write(\"\\n\")\n",
    "    outfile.write(\"\\t\".join(map(str, losses_val)))\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde69b5-127d-4575-941e-2326ab1a4a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
